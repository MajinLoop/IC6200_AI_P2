digraph {
	graph [size="19.2,19.2"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1635123025536 [label="
 (1, 3)" fillcolor=darkolivegreen1]
	1635124368528 [label=AddmmBackward0]
	1635124369920 -> 1635124368528
	1635017743392 [label="fc2.bias
 (3)" fillcolor=lightblue]
	1635017743392 -> 1635124369920
	1635124369920 [label=AccumulateGrad]
	1635124367712 -> 1635124368528
	1635124367712 [label=MulBackward0]
	1635124371360 -> 1635124367712
	1635124371360 [label=ReluBackward0]
	1635124370784 -> 1635124371360
	1635124370784 [label=AddmmBackward0]
	1635124369536 -> 1635124370784
	1635017742592 [label="fc1.bias
 (64)" fillcolor=lightblue]
	1635017742592 -> 1635124369536
	1635124369536 [label=AccumulateGrad]
	1635124370448 -> 1635124370784
	1635124370448 [label=ViewBackward0]
	1635124473760 -> 1635124370448
	1635124473760 [label=MaxPool2DWithIndicesBackward0]
	1635123984704 -> 1635124473760
	1635123984704 [label=ReluBackward0]
	1635123982496 -> 1635123984704
	1635123982496 [label=ConvolutionBackward0]
	1635124721312 -> 1635123982496
	1635124721312 [label=MaxPool2DWithIndicesBackward0]
	1635124766320 -> 1635124721312
	1635124766320 [label=CatBackward0]
	1635124765456 -> 1635124766320
	1635124765456 [label=ConvolutionBackward0]
	1635124872816 -> 1635124765456
	1635124872816 [label=MaxPool2DWithIndicesBackward0]
	1635124872768 -> 1635124872816
	1635124872768 [label=ReluBackward0]
	1635124872240 -> 1635124872768
	1635124872240 [label=ConvolutionBackward0]
	1635124690800 -> 1635124872240
	1635017854464 [label="conv1.weight
 (32, 1, 3, 3)" fillcolor=lightblue]
	1635017854464 -> 1635124690800
	1635124690800 [label=AccumulateGrad]
	1635124690416 -> 1635124872240
	1635017854544 [label="conv1.bias
 (32)" fillcolor=lightblue]
	1635017854544 -> 1635124690416
	1635124690416 [label=AccumulateGrad]
	1635124872960 -> 1635124765456
	1635017854864 [label="inception1.branch1x1.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	1635017854864 -> 1635124872960
	1635124872960 [label=AccumulateGrad]
	1635124873872 -> 1635124765456
	1635017853504 [label="inception1.branch1x1.bias
 (32)" fillcolor=lightblue]
	1635017853504 -> 1635124873872
	1635124873872 [label=AccumulateGrad]
	1635124766272 -> 1635124766320
	1635124766272 [label=ConvolutionBackward0]
	1635124874688 -> 1635124766272
	1635124874688 [label=ConvolutionBackward0]
	1635124872816 -> 1635124874688
	1635126874896 -> 1635124874688
	1635017850944 [label="inception1.branch3x3_1.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	1635017850944 -> 1635126874896
	1635126874896 [label=AccumulateGrad]
	1635126877104 -> 1635124874688
	1635017854784 [label="inception1.branch3x3_1.bias
 (32)" fillcolor=lightblue]
	1635017854784 -> 1635126877104
	1635126877104 [label=AccumulateGrad]
	1635124872096 -> 1635124766272
	1635017854224 [label="inception1.branch3x3_2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1635017854224 -> 1635124872096
	1635124872096 [label=AccumulateGrad]
	1635124690224 -> 1635124766272
	1635017853664 [label="inception1.branch3x3_2.bias
 (32)" fillcolor=lightblue]
	1635017853664 -> 1635124690224
	1635124690224 [label=AccumulateGrad]
	1635124765696 -> 1635124766320
	1635124765696 [label=ConvolutionBackward0]
	1635124690464 -> 1635124765696
	1635124690464 [label=ConvolutionBackward0]
	1635124872816 -> 1635124690464
	1635126877056 -> 1635124690464
	1635017853824 [label="inception1.branch5x5_1.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	1635017853824 -> 1635126877056
	1635126877056 [label=AccumulateGrad]
	1635126876912 -> 1635124690464
	1635017852304 [label="inception1.branch5x5_1.bias
 (32)" fillcolor=lightblue]
	1635017852304 -> 1635126876912
	1635126876912 [label=AccumulateGrad]
	1635126876864 -> 1635124765696
	1635017743312 [label="inception1.branch5x5_2.weight
 (32, 32, 5, 5)" fillcolor=lightblue]
	1635017743312 -> 1635126876864
	1635126876864 [label=AccumulateGrad]
	1635126875904 -> 1635124765696
	1635017743072 [label="inception1.branch5x5_2.bias
 (32)" fillcolor=lightblue]
	1635017743072 -> 1635126875904
	1635126875904 [label=AccumulateGrad]
	1635124765840 -> 1635124766320
	1635124765840 [label=ConvolutionBackward0]
	1635126876240 -> 1635124765840
	1635126876240 [label=MaxPool2DWithIndicesBackward0]
	1635124872816 -> 1635126876240
	1635126875040 -> 1635124765840
	1635017743232 [label="inception1.branch_pool.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	1635017743232 -> 1635126875040
	1635126875040 [label=AccumulateGrad]
	1635126877008 -> 1635124765840
	1635017742832 [label="inception1.branch_pool.bias
 (32)" fillcolor=lightblue]
	1635017742832 -> 1635126877008
	1635126877008 [label=AccumulateGrad]
	1635124721168 -> 1635123982496
	1635017743472 [label="conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1635017743472 -> 1635124721168
	1635124721168 [label=AccumulateGrad]
	1635123982400 -> 1635123982496
	1635017741552 [label="conv2.bias
 (128)" fillcolor=lightblue]
	1635017741552 -> 1635123982400
	1635123982400 [label=AccumulateGrad]
	1635124471312 -> 1635124370784
	1635124471312 [label=TBackward0]
	1635123984800 -> 1635124471312
	1635017741632 [label="fc1.weight
 (64, 32768)" fillcolor=lightblue]
	1635017741632 -> 1635123984800
	1635123984800 [label=AccumulateGrad]
	1635124370880 -> 1635124368528
	1635124370880 [label=TBackward0]
	1635123984752 -> 1635124370880
	1635017742672 [label="fc2.weight
 (3, 64)" fillcolor=lightblue]
	1635017742672 -> 1635123984752
	1635123984752 [label=AccumulateGrad]
	1635124368528 -> 1635123025536
}
