digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1852327747968 [label="
 (1, 3)" fillcolor=darkolivegreen1]
	1852425340144 [label=AddmmBackward0]
	1852425340240 -> 1852425340144
	1852043632448 [label="fc.bias
 (3)" fillcolor=lightblue]
	1852043632448 -> 1852425340240
	1852425340240 [label=AccumulateGrad]
	1852425340192 -> 1852425340144
	1852425340192 [label=ViewBackward0]
	1852425339712 -> 1852425340192
	1852425339712 [label=MeanBackward1]
	1852425339040 -> 1852425339712
	1852425339040 [label=ReluBackward0]
	1852425340672 -> 1852425339040
	1852425340672 [label=AddBackward0]
	1852425340912 -> 1852425340672
	1852425340912 [label=CudnnBatchNormBackward0]
	1852425340288 -> 1852425340912
	1852425340288 [label=ConvolutionBackward0]
	1852425340432 -> 1852425340288
	1852425340432 [label=ReluBackward0]
	1852425339808 -> 1852425340432
	1852425339808 [label=CudnnBatchNormBackward0]
	1852425340000 -> 1852425339808
	1852425340000 [label=ConvolutionBackward0]
	1852425339280 -> 1852425340000
	1852425339280 [label=ReluBackward0]
	1852425339760 -> 1852425339280
	1852425339760 [label=CudnnBatchNormBackward0]
	1852425339136 -> 1852425339760
	1852425339136 [label=ConvolutionBackward0]
	1852425341104 -> 1852425339136
	1852425341104 [label=ReluBackward0]
	1852043890992 -> 1852425341104
	1852043890992 [label=AddBackward0]
	1852043891184 -> 1852043890992
	1852043891184 [label=CudnnBatchNormBackward0]
	1852425265360 -> 1852043891184
	1852425265360 [label=ConvolutionBackward0]
	1852425265888 -> 1852425265360
	1852425265888 [label=ReluBackward0]
	1852425266368 -> 1852425265888
	1852425266368 [label=CudnnBatchNormBackward0]
	1852425266848 -> 1852425266368
	1852425266848 [label=ConvolutionBackward0]
	1852425267472 -> 1852425266848
	1852425267472 [label=ReluBackward0]
	1852425267952 -> 1852425267472
	1852425267952 [label=CudnnBatchNormBackward0]
	1852425268048 -> 1852425267952
	1852425268048 [label=ConvolutionBackward0]
	1852043891856 -> 1852425268048
	1852043891856 [label=ReluBackward0]
	1852425269008 -> 1852043891856
	1852425269008 [label=AddBackward0]
	1852425266896 -> 1852425269008
	1852425266896 [label=CudnnBatchNormBackward0]
	1852425269152 -> 1852425266896
	1852425269152 [label=ConvolutionBackward0]
	1852425268624 -> 1852425269152
	1852425268624 [label=ReluBackward0]
	1852425268864 -> 1852425268624
	1852425268864 [label=CudnnBatchNormBackward0]
	1852425268192 -> 1852425268864
	1852425268192 [label=ConvolutionBackward0]
	1852425268144 -> 1852425268192
	1852425268144 [label=ReluBackward0]
	1852425267184 -> 1852425268144
	1852425267184 [label=CudnnBatchNormBackward0]
	1852425267568 -> 1852425267184
	1852425267568 [label=ConvolutionBackward0]
	1852425266656 -> 1852425267568
	1852425266656 [label=ReluBackward0]
	1852425267232 -> 1852425266656
	1852425267232 [label=AddBackward0]
	1852425267280 -> 1852425267232
	1852425267280 [label=CudnnBatchNormBackward0]
	1852425266560 -> 1852425267280
	1852425266560 [label=ConvolutionBackward0]
	1852425265984 -> 1852425266560
	1852425265984 [label=ReluBackward0]
	1852425266224 -> 1852425265984
	1852425266224 [label=CudnnBatchNormBackward0]
	1852425265456 -> 1852425266224
	1852425265456 [label=ConvolutionBackward0]
	1852425266704 -> 1852425265456
	1852425266704 [label=ReluBackward0]
	1852425266512 -> 1852425266704
	1852425266512 [label=CudnnBatchNormBackward0]
	1852425290224 -> 1852425266512
	1852425290224 [label=ConvolutionBackward0]
	1852425267088 -> 1852425290224
	1852425267088 [label=ReluBackward0]
	1852425291184 -> 1852425267088
	1852425291184 [label=AddBackward0]
	1852425291664 -> 1852425291184
	1852425291664 [label=CudnnBatchNormBackward0]
	1852425292144 -> 1852425291664
	1852425292144 [label=ConvolutionBackward0]
	1852425292720 -> 1852425292144
	1852425292720 [label=ReluBackward0]
	1852425293200 -> 1852425292720
	1852425293200 [label=CudnnBatchNormBackward0]
	1852425290752 -> 1852425293200
	1852425290752 [label=ConvolutionBackward0]
	1852425293728 -> 1852425290752
	1852425293728 [label=ReluBackward0]
	1852425293536 -> 1852425293728
	1852425293536 [label=CudnnBatchNormBackward0]
	1852425293488 -> 1852425293536
	1852425293488 [label=ConvolutionBackward0]
	1852425291616 -> 1852425293488
	1852425291616 [label=ReluBackward0]
	1852425292480 -> 1852425291616
	1852425292480 [label=AddBackward0]
	1852425292864 -> 1852425292480
	1852425292864 [label=CudnnBatchNormBackward0]
	1852425291952 -> 1852425292864
	1852425291952 [label=ConvolutionBackward0]
	1852425292528 -> 1852425291952
	1852425292528 [label=ReluBackward0]
	1852425291424 -> 1852425292528
	1852425291424 [label=CudnnBatchNormBackward0]
	1852425291808 -> 1852425291424
	1852425291808 [label=ConvolutionBackward0]
	1852425291328 -> 1852425291808
	1852425291328 [label=ReluBackward0]
	1852425290416 -> 1852425291328
	1852425290416 [label=CudnnBatchNormBackward0]
	1852425290896 -> 1852425290416
	1852425290896 [label=ConvolutionBackward0]
	1852425292912 -> 1852425290896
	1852425292912 [label=ReluBackward0]
	1852425290512 -> 1852425292912
	1852425290512 [label=AddBackward0]
	1852425289792 -> 1852425290512
	1852425289792 [label=CudnnBatchNormBackward0]
	1852425291376 -> 1852425289792
	1852425291376 [label=ConvolutionBackward0]
	1852425292048 -> 1852425291376
	1852425292048 [label=ReluBackward0]
	1852425241072 -> 1852425292048
	1852425241072 [label=CudnnBatchNormBackward0]
	1852425241552 -> 1852425241072
	1852425241552 [label=ConvolutionBackward0]
	1852425242080 -> 1852425241552
	1852425242080 [label=ReluBackward0]
	1852425242608 -> 1852425242080
	1852425242608 [label=CudnnBatchNormBackward0]
	1852425242752 -> 1852425242608
	1852425242752 [label=ConvolutionBackward0]
	1852425289840 -> 1852425242752
	1852425289840 [label=ReluBackward0]
	1852425243616 -> 1852425289840
	1852425243616 [label=AddBackward0]
	1852425244144 -> 1852425243616
	1852425244144 [label=CudnnBatchNormBackward0]
	1852425244288 -> 1852425244144
	1852425244288 [label=ConvolutionBackward0]
	1852425244384 -> 1852425244288
	1852425244384 [label=ReluBackward0]
	1852425244624 -> 1852425244384
	1852425244624 [label=CudnnBatchNormBackward0]
	1852425243760 -> 1852425244624
	1852425243760 [label=ConvolutionBackward0]
	1852425243328 -> 1852425243760
	1852425243328 [label=ReluBackward0]
	1852425243472 -> 1852425243328
	1852425243472 [label=CudnnBatchNormBackward0]
	1852425242896 -> 1852425243472
	1852425242896 [label=ConvolutionBackward0]
	1852425243712 -> 1852425242896
	1852425243712 [label=ReluBackward0]
	1852425243040 -> 1852425243712
	1852425243040 [label=AddBackward0]
	1852425243808 -> 1852425243040
	1852425243808 [label=CudnnBatchNormBackward0]
	1852425242320 -> 1852425243808
	1852425242320 [label=ConvolutionBackward0]
	1852425241840 -> 1852425242320
	1852425241840 [label=ReluBackward0]
	1852425242224 -> 1852425241840
	1852425242224 [label=CudnnBatchNormBackward0]
	1852425241216 -> 1852425242224
	1852425241216 [label=ConvolutionBackward0]
	1852425240688 -> 1852425241216
	1852425240688 [label=ReluBackward0]
	1852425240928 -> 1852425240688
	1852425240928 [label=CudnnBatchNormBackward0]
	1852425241984 -> 1852425240928
	1852425241984 [label=ConvolutionBackward0]
	1852425241936 -> 1852425241984
	1852425241936 [label=ReluBackward0]
	1852425195680 -> 1852425241936
	1852425195680 [label=AddBackward0]
	1852425196112 -> 1852425195680
	1852425196112 [label=CudnnBatchNormBackward0]
	1852425196256 -> 1852425196112
	1852425196256 [label=ConvolutionBackward0]
	1852425196784 -> 1852425196256
	1852425196784 [label=ReluBackward0]
	1852425197264 -> 1852425196784
	1852425197264 [label=CudnnBatchNormBackward0]
	1852425197696 -> 1852425197264
	1852425197696 [label=ConvolutionBackward0]
	1852425198320 -> 1852425197696
	1852425198320 [label=ReluBackward0]
	1852425199280 -> 1852425198320
	1852425199280 [label=CudnnBatchNormBackward0]
	1852425199424 -> 1852425199280
	1852425199424 [label=ConvolutionBackward0]
	1852425195728 -> 1852425199424
	1852425195728 [label=ReluBackward0]
	1852425198560 -> 1852425195728
	1852425198560 [label=AddBackward0]
	1852425198944 -> 1852425198560
	1852425198944 [label=CudnnBatchNormBackward0]
	1852425198176 -> 1852425198944
	1852425198176 [label=ConvolutionBackward0]
	1852425198512 -> 1852425198176
	1852425198512 [label=ReluBackward0]
	1852425198464 -> 1852425198512
	1852425198464 [label=CudnnBatchNormBackward0]
	1852425198656 -> 1852425198464
	1852425198656 [label=ConvolutionBackward0]
	1852425340480 -> 1852425198656
	1852425340480 [label=ReluBackward0]
	1852425342928 -> 1852425340480
	1852425342928 [label=CudnnBatchNormBackward0]
	1852425342352 -> 1852425342928
	1852425342352 [label=ConvolutionBackward0]
	1852425199040 -> 1852425342352
	1852425199040 [label=ReluBackward0]
	1852425342256 -> 1852425199040
	1852425342256 [label=AddBackward0]
	1852425312240 -> 1852425342256
	1852425312240 [label=CudnnBatchNormBackward0]
	1852425311184 -> 1852425312240
	1852425311184 [label=ConvolutionBackward0]
	1852425291568 -> 1852425311184
	1852425291568 [label=ReluBackward0]
	1852425290032 -> 1852425291568
	1852425290032 [label=CudnnBatchNormBackward0]
	1852425266800 -> 1852425290032
	1852425266800 [label=ConvolutionBackward0]
	1852425265216 -> 1852425266800
	1852425265216 [label=ReluBackward0]
	1852472195296 -> 1852425265216
	1852472195296 [label=CudnnBatchNormBackward0]
	1852472194816 -> 1852472195296
	1852472194816 [label=ConvolutionBackward0]
	1852425312768 -> 1852472194816
	1852425312768 [label=ReluBackward0]
	1852472193328 -> 1852425312768
	1852472193328 [label=AddBackward0]
	1852472196016 -> 1852472193328
	1852472196016 [label=CudnnBatchNormBackward0]
	1852472196592 -> 1852472196016
	1852472196592 [label=ConvolutionBackward0]
	1852472196976 -> 1852472196592
	1852472196976 [label=ReluBackward0]
	1852425240976 -> 1852472196976
	1852425240976 [label=CudnnBatchNormBackward0]
	1852425243088 -> 1852425240976
	1852425243088 [label=ConvolutionBackward0]
	1852425198032 -> 1852425243088
	1852425198032 [label=ReluBackward0]
	1852425197360 -> 1852425198032
	1852425197360 [label=CudnnBatchNormBackward0]
	1852425197552 -> 1852425197360
	1852425197552 [label=ConvolutionBackward0]
	1852425196880 -> 1852425197552
	1852425196880 [label=ReluBackward0]
	1852425195920 -> 1852425196880
	1852425195920 [label=AddBackward0]
	1852425196304 -> 1852425195920
	1852425196304 [label=CudnnBatchNormBackward0]
	1852425196544 -> 1852425196304
	1852425196544 [label=ConvolutionBackward0]
	1852425195776 -> 1852425196544
	1852425195776 [label=ReluBackward0]
	1852425197600 -> 1852425195776
	1852425197600 [label=CudnnBatchNormBackward0]
	1852425198272 -> 1852425197600
	1852425198272 [label=ConvolutionBackward0]
	1852425197840 -> 1852425198272
	1852425197840 [label=ReluBackward0]
	1852425175440 -> 1852425197840
	1852425175440 [label=CudnnBatchNormBackward0]
	1852425175536 -> 1852425175440
	1852425175536 [label=ConvolutionBackward0]
	1852425196400 -> 1852425175536
	1852425196400 [label=ReluBackward0]
	1852425176544 -> 1852425196400
	1852425176544 [label=AddBackward0]
	1852425177024 -> 1852425176544
	1852425177024 [label=CudnnBatchNormBackward0]
	1852425177552 -> 1852425177024
	1852425177552 [label=ConvolutionBackward0]
	1852425178080 -> 1852425177552
	1852425178080 [label=ReluBackward0]
	1852425178224 -> 1852425178080
	1852425178224 [label=CudnnBatchNormBackward0]
	1852425178656 -> 1852425178224
	1852425178656 [label=ConvolutionBackward0]
	1852425178992 -> 1852425178656
	1852425178992 [label=ReluBackward0]
	1852425178272 -> 1852425178992
	1852425178272 [label=CudnnBatchNormBackward0]
	1852425178464 -> 1852425178272
	1852425178464 [label=ConvolutionBackward0]
	1852425176640 -> 1852425178464
	1852425176640 [label=ReluBackward0]
	1852425177792 -> 1852425176640
	1852425177792 [label=AddBackward0]
	1852425178416 -> 1852425177792
	1852425178416 [label=CudnnBatchNormBackward0]
	1852425176832 -> 1852425178416
	1852425176832 [label=ConvolutionBackward0]
	1852425177408 -> 1852425176832
	1852425177408 [label=ReluBackward0]
	1852425176736 -> 1852425177408
	1852425176736 [label=CudnnBatchNormBackward0]
	1852425176880 -> 1852425176736
	1852425176880 [label=ConvolutionBackward0]
	1852425176160 -> 1852425176880
	1852425176160 [label=ReluBackward0]
	1852425176400 -> 1852425176160
	1852425176400 [label=CudnnBatchNormBackward0]
	1852425175728 -> 1852425176400
	1852425175728 [label=ConvolutionBackward0]
	1852425175872 -> 1852425175728
	1852425175872 [label=MaxPool2DWithIndicesBackward0]
	1852425175152 -> 1852425175872
	1852425175152 [label=ReluBackward0]
	1852425178704 -> 1852425175152
	1852425178704 [label=CudnnBatchNormBackward0]
	1852425175344 -> 1852425178704
	1852425175344 [label=ConvolutionBackward0]
	1852425176112 -> 1852425175344
	1851941874080 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	1851941874080 -> 1852425176112
	1852425176112 [label=AccumulateGrad]
	1852425175296 -> 1852425178704
	1851941873920 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1851941873920 -> 1852425175296
	1852425175296 [label=AccumulateGrad]
	1852425175200 -> 1852425178704
	1851941874160 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1851941874160 -> 1852425175200
	1852425175200 [label=AccumulateGrad]
	1852425175824 -> 1852425175728
	1851941875200 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1851941875200 -> 1852425175824
	1852425175824 [label=AccumulateGrad]
	1852425175248 -> 1852425176400
	1851941875280 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1851941875280 -> 1852425175248
	1852425175248 [label=AccumulateGrad]
	1852425176208 -> 1852425176400
	1851941875360 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1851941875360 -> 1852425176208
	1852425176208 [label=AccumulateGrad]
	1852425176256 -> 1852425176880
	1851941925088 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1851941925088 -> 1852425176256
	1852425176256 [label=AccumulateGrad]
	1852425176688 -> 1852425176736
	1851941925008 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1851941925008 -> 1852425176688
	1852425176688 [label=AccumulateGrad]
	1852425176304 -> 1852425176736
	1851941925168 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1851941925168 -> 1852425176304
	1852425176304 [label=AccumulateGrad]
	1852425177360 -> 1852425176832
	1851941925568 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1851941925568 -> 1852425177360
	1852425177360 [label=AccumulateGrad]
	1852425177264 -> 1852425178416
	1851941925648 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	1851941925648 -> 1852425177264
	1852425177264 [label=AccumulateGrad]
	1852425177984 -> 1852425178416
	1851941925728 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	1851941925728 -> 1852425177984
	1852425177984 [label=AccumulateGrad]
	1852425177936 -> 1852425177792
	1852425177936 [label=CudnnBatchNormBackward0]
	1852425175776 -> 1852425177936
	1852425175776 [label=ConvolutionBackward0]
	1852425175872 -> 1852425175776
	1852425175632 -> 1852425175776
	1851941874640 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1851941874640 -> 1852425175632
	1852425175632 [label=AccumulateGrad]
	1852425177216 -> 1852425177936
	1851941874720 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1851941874720 -> 1852425177216
	1852425177216 [label=AccumulateGrad]
	1852425179040 -> 1852425177936
	1851941874800 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1851941874800 -> 1852425179040
	1852425179040 [label=AccumulateGrad]
	1852425177744 -> 1852425178464
	1851941926048 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1851941926048 -> 1852425177744
	1852425177744 [label=AccumulateGrad]
	1852425178320 -> 1852425178272
	1851941926128 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1851941926128 -> 1852425178320
	1852425178320 [label=AccumulateGrad]
	1852425177888 -> 1852425178272
	1851941926208 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1851941926208 -> 1852425177888
	1852425177888 [label=AccumulateGrad]
	1852425178800 -> 1852425178656
	1851941926688 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1851941926688 -> 1852425178800
	1852425178800 [label=AccumulateGrad]
	1852425178608 -> 1852425178224
	1851941926448 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1851941926448 -> 1852425178608
	1852425178608 [label=AccumulateGrad]
	1852425178128 -> 1852425178224
	1851941926848 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1851941926848 -> 1852425178128
	1852425178128 [label=AccumulateGrad]
	1852425177648 -> 1852425177552
	1851941927248 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1851941927248 -> 1852425177648
	1852425177648 [label=AccumulateGrad]
	1852425177168 -> 1852425177024
	1851941927328 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	1851941927328 -> 1852425177168
	1852425177168 [label=AccumulateGrad]
	1852425177072 -> 1852425177024
	1851941927408 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	1851941927408 -> 1852425177072
	1852425177072 [label=AccumulateGrad]
	1852425176640 -> 1852425176544
	1852425176064 -> 1852425175536
	1851941927808 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1851941927808 -> 1852425176064
	1852425176064 [label=AccumulateGrad]
	1852425175488 -> 1852425175440
	1851941927888 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	1851941927888 -> 1852425175488
	1852425175488 [label=AccumulateGrad]
	1852425178032 -> 1852425175440
	1851941927968 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	1851941927968 -> 1852425178032
	1852425178032 [label=AccumulateGrad]
	1852425175920 -> 1852425198272
	1851941928448 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1851941928448 -> 1852425175920
	1852425175920 [label=AccumulateGrad]
	1852425196016 -> 1852425197600
	1851941928368 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	1851941928368 -> 1852425196016
	1852425196016 [label=AccumulateGrad]
	1852425195824 -> 1852425197600
	1851941928528 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	1851941928528 -> 1852425195824
	1852425195824 [label=AccumulateGrad]
	1852425195872 -> 1852425196544
	1851942015040 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1851942015040 -> 1852425195872
	1852425195872 [label=AccumulateGrad]
	1852425196496 -> 1852425196304
	1851942015120 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	1851942015120 -> 1852425196496
	1852425196496 [label=AccumulateGrad]
	1852425196352 -> 1852425196304
	1851942015200 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	1851942015200 -> 1852425196352
	1852425196352 [label=AccumulateGrad]
	1852425196400 -> 1852425195920
	1852425196832 -> 1852425197552
	1851942016240 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1851942016240 -> 1852425196832
	1852425196832 [label=AccumulateGrad]
	1852425197408 -> 1852425197360
	1851942016320 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1851942016320 -> 1852425197408
	1852425197408 [label=AccumulateGrad]
	1852425197888 -> 1852425197360
	1851942016400 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1851942016400 -> 1852425197888
	1852425197888 [label=AccumulateGrad]
	1852425198704 -> 1852425243088
	1851942016880 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1851942016880 -> 1852425198704
	1852425198704 [label=AccumulateGrad]
	1852425242032 -> 1852425240976
	1851942016800 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1851942016800 -> 1852425242032
	1852425242032 [label=AccumulateGrad]
	1852425197504 -> 1852425240976
	1851942016960 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1851942016960 -> 1852425197504
	1852425197504 [label=AccumulateGrad]
	1852472197024 -> 1852472196592
	1851942017360 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1851942017360 -> 1852472197024
	1852472197024 [label=AccumulateGrad]
	1852472196352 -> 1852472196016
	1851942017440 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	1851942017440 -> 1852472196352
	1852472196352 [label=AccumulateGrad]
	1852472196208 -> 1852472196016
	1851942017520 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	1851942017520 -> 1852472196208
	1852472196208 [label=AccumulateGrad]
	1852472193136 -> 1852472193328
	1852472193136 [label=CudnnBatchNormBackward0]
	1852425241504 -> 1852472193136
	1852425241504 [label=ConvolutionBackward0]
	1852425196880 -> 1852425241504
	1852425196448 -> 1852425241504
	1851942015600 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1851942015600 -> 1852425196448
	1852425196448 [label=AccumulateGrad]
	1852425242560 -> 1852472193136
	1851942015680 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1851942015680 -> 1852425242560
	1852425242560 [label=AccumulateGrad]
	1852472196736 -> 1852472193136
	1851942015760 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1851942015760 -> 1852472196736
	1852472196736 [label=AccumulateGrad]
	1852472193808 -> 1852472194816
	1851942017840 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1851942017840 -> 1852472193808
	1852472193808 [label=AccumulateGrad]
	1852472194960 -> 1852472195296
	1851942017920 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1851942017920 -> 1852472194960
	1852472194960 [label=AccumulateGrad]
	1852472195728 -> 1852472195296
	1851942018000 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1851942018000 -> 1852472195728
	1852472195728 [label=AccumulateGrad]
	1852425265744 -> 1852425266800
	1851942018480 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1851942018480 -> 1852425265744
	1852425265744 [label=AccumulateGrad]
	1852425267328 -> 1852425290032
	1851942018400 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1851942018400 -> 1852425267328
	1852425267328 [label=AccumulateGrad]
	1852425267856 -> 1852425290032
	1851942018560 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1851942018560 -> 1852425267856
	1852425267856 [label=AccumulateGrad]
	1852425292096 -> 1852425311184
	1851942018960 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1851942018960 -> 1852425292096
	1852425292096 [label=AccumulateGrad]
	1852425310656 -> 1852425312240
	1852043059264 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	1852043059264 -> 1852425310656
	1852425310656 [label=AccumulateGrad]
	1852425293680 -> 1852425312240
	1852043059344 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	1852043059344 -> 1852425293680
	1852425293680 [label=AccumulateGrad]
	1852425312768 -> 1852425342256
	1852425341488 -> 1852425342352
	1852043059744 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1852043059744 -> 1852425341488
	1852425341488 [label=AccumulateGrad]
	1852425342496 -> 1852425342928
	1852043059824 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	1852043059824 -> 1852425342496
	1852425342496 [label=AccumulateGrad]
	1852425338992 -> 1852425342928
	1852043059904 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	1852043059904 -> 1852425338992
	1852425338992 [label=AccumulateGrad]
	1852425341008 -> 1852425198656
	1852043060384 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1852043060384 -> 1852425341008
	1852425341008 [label=AccumulateGrad]
	1852425198608 -> 1852425198464
	1852043060304 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	1852043060304 -> 1852425198608
	1852425198608 [label=AccumulateGrad]
	1852425199328 -> 1852425198464
	1852043060464 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	1852043060464 -> 1852425199328
	1852425199328 [label=AccumulateGrad]
	1852425198368 -> 1852425198176
	1852043060864 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1852043060864 -> 1852425198368
	1852425198368 [label=AccumulateGrad]
	1852425198752 -> 1852425198944
	1852043060944 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	1852043060944 -> 1852425198752
	1852425198752 [label=AccumulateGrad]
	1852425198992 -> 1852425198944
	1852043061024 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	1852043061024 -> 1852425198992
	1852425198992 [label=AccumulateGrad]
	1852425199040 -> 1852425198560
	1852425199472 -> 1852425199424
	1852043061424 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1852043061424 -> 1852425199472
	1852425199472 [label=AccumulateGrad]
	1852425199376 -> 1852425199280
	1852043061504 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	1852043061504 -> 1852425199376
	1852425199376 [label=AccumulateGrad]
	1852425198800 -> 1852425199280
	1852043061584 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	1852043061584 -> 1852425198800
	1852425198800 [label=AccumulateGrad]
	1852425198224 -> 1852425197696
	1852043062064 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1852043062064 -> 1852425198224
	1852425198224 [label=AccumulateGrad]
	1852425197312 -> 1852425197264
	1852043061984 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	1852043061984 -> 1852425197312
	1852425197312 [label=AccumulateGrad]
	1852425197168 -> 1852425197264
	1852043062144 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	1852043062144 -> 1852425197168
	1852425197168 [label=AccumulateGrad]
	1852425196736 -> 1852425196256
	1852043062544 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1852043062544 -> 1852425196736
	1852425196736 [label=AccumulateGrad]
	1852425196208 -> 1852425196112
	1852043062624 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	1852043062624 -> 1852425196208
	1852425196208 [label=AccumulateGrad]
	1852425196160 -> 1852425196112
	1852043062704 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	1852043062704 -> 1852425196160
	1852425196160 [label=AccumulateGrad]
	1852425195728 -> 1852425195680
	1852425240832 -> 1852425241984
	1852043158048 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	1852043158048 -> 1852425240832
	1852425240832 [label=AccumulateGrad]
	1852425241312 -> 1852425240928
	1852043158128 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1852043158128 -> 1852425241312
	1852425241312 [label=AccumulateGrad]
	1852425240736 -> 1852425240928
	1852043158208 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1852043158208 -> 1852425240736
	1852425240736 [label=AccumulateGrad]
	1852425241456 -> 1852425241216
	1852043158688 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1852043158688 -> 1852425241456
	1852425241456 [label=AccumulateGrad]
	1852425242704 -> 1852425242224
	1852043158608 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1852043158608 -> 1852425242704
	1852425242704 [label=AccumulateGrad]
	1852425241744 -> 1852425242224
	1852043158768 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1852043158768 -> 1852425241744
	1852425241744 [label=AccumulateGrad]
	1852425241360 -> 1852425242320
	1852043159168 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1852043159168 -> 1852425241360
	1852425241360 [label=AccumulateGrad]
	1852425242272 -> 1852425243808
	1852043159248 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	1852043159248 -> 1852425242272
	1852425242272 [label=AccumulateGrad]
	1852425242368 -> 1852425243808
	1852043159328 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	1852043159328 -> 1852425242368
	1852425242368 [label=AccumulateGrad]
	1852425241888 -> 1852425243040
	1852425241888 [label=CudnnBatchNormBackward0]
	1852425243232 -> 1852425241888
	1852425243232 [label=ConvolutionBackward0]
	1852425241936 -> 1852425243232
	1852425240784 -> 1852425243232
	1852043063104 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	1852043063104 -> 1852425240784
	1852425240784 [label=AccumulateGrad]
	1852425242512 -> 1852425241888
	1852043063184 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	1852043063184 -> 1852425242512
	1852425242512 [label=AccumulateGrad]
	1852425242464 -> 1852425241888
	1852043157568 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	1852043157568 -> 1852425242464
	1852425242464 [label=AccumulateGrad]
	1852425242848 -> 1852425242896
	1852043159648 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1852043159648 -> 1852425242848
	1852425242848 [label=AccumulateGrad]
	1852425242416 -> 1852425243472
	1852043159728 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1852043159728 -> 1852425242416
	1852425242416 [label=AccumulateGrad]
	1852425242944 -> 1852425243472
	1852043159808 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1852043159808 -> 1852425242944
	1852425242944 [label=AccumulateGrad]
	1852425244048 -> 1852425243760
	1852043160288 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1852043160288 -> 1852425244048
	1852425244048 [label=AccumulateGrad]
	1852425243904 -> 1852425244624
	1852043160208 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1852043160208 -> 1852425243904
	1852425243904 [label=AccumulateGrad]
	1852425244336 -> 1852425244624
	1852043160368 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1852043160368 -> 1852425244336
	1852425244336 [label=AccumulateGrad]
	1852425244528 -> 1852425244288
	1852043160768 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1852043160768 -> 1852425244528
	1852425244528 [label=AccumulateGrad]
	1852425244240 -> 1852425244144
	1852043160848 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	1852043160848 -> 1852425244240
	1852425244240 [label=AccumulateGrad]
	1852425244192 -> 1852425244144
	1852043160928 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	1852043160928 -> 1852425244192
	1852425244192 [label=AccumulateGrad]
	1852425243712 -> 1852425243616
	1852425243664 -> 1852425242752
	1852043161328 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1852043161328 -> 1852425243664
	1852425243664 [label=AccumulateGrad]
	1852425242656 -> 1852425242608
	1852043161408 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	1852043161408 -> 1852425242656
	1852425242656 [label=AccumulateGrad]
	1852425242128 -> 1852425242608
	1852043161488 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	1852043161488 -> 1852425242128
	1852425242128 [label=AccumulateGrad]
	1852425241696 -> 1852425241552
	1852043264464 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1852043264464 -> 1852425241696
	1852425241696 [label=AccumulateGrad]
	1852425241168 -> 1852425241072
	1852043264384 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	1852043264384 -> 1852425241168
	1852425241168 [label=AccumulateGrad]
	1852425241024 -> 1852425241072
	1852043264544 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	1852043264544 -> 1852425241024
	1852425241024 [label=AccumulateGrad]
	1852425291280 -> 1852425291376
	1852043264944 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1852043264944 -> 1852425291280
	1852425291280 [label=AccumulateGrad]
	1852425289984 -> 1852425289792
	1852043265024 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	1852043265024 -> 1852425289984
	1852425289984 [label=AccumulateGrad]
	1852425289936 -> 1852425289792
	1852043265104 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	1852043265104 -> 1852425289936
	1852425289936 [label=AccumulateGrad]
	1852425289840 -> 1852425290512
	1852425290320 -> 1852425290896
	1852043265504 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1852043265504 -> 1852425290320
	1852425290320 [label=AccumulateGrad]
	1852425290944 -> 1852425290416
	1852043265584 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	1852043265584 -> 1852425290944
	1852425290944 [label=AccumulateGrad]
	1852425291520 -> 1852425290416
	1852043265664 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	1852043265664 -> 1852425291520
	1852425291520 [label=AccumulateGrad]
	1852425291232 -> 1852425291808
	1852043266144 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1852043266144 -> 1852425291232
	1852425291232 [label=AccumulateGrad]
	1852425291904 -> 1852425291424
	1852043266064 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	1852043266064 -> 1852425291904
	1852425291904 [label=AccumulateGrad]
	1852425292576 -> 1852425291424
	1852043266224 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	1852043266224 -> 1852425292576
	1852425292576 [label=AccumulateGrad]
	1852425292384 -> 1852425291952
	1852043266624 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1852043266624 -> 1852425292384
	1852425292384 [label=AccumulateGrad]
	1852425293104 -> 1852425292864
	1852043266704 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	1852043266704 -> 1852425293104
	1852425293104 [label=AccumulateGrad]
	1852425293056 -> 1852425292864
	1852043266784 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	1852043266784 -> 1852425293056
	1852425293056 [label=AccumulateGrad]
	1852425292912 -> 1852425292480
	1852425293632 -> 1852425293488
	1852043267184 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1852043267184 -> 1852425293632
	1852425293632 [label=AccumulateGrad]
	1852425293008 -> 1852425293536
	1852043267264 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	1852043267264 -> 1852425293008
	1852425293008 [label=AccumulateGrad]
	1852425293776 -> 1852425293536
	1852043267344 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	1852043267344 -> 1852425293776
	1852425293776 [label=AccumulateGrad]
	1852425293344 -> 1852425290752
	1852043267824 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1852043267824 -> 1852425293344
	1852425293344 [label=AccumulateGrad]
	1852425293248 -> 1852425293200
	1852043267744 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	1852043267744 -> 1852425293248
	1852425293248 [label=AccumulateGrad]
	1852425292768 -> 1852425293200
	1852043267904 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	1852043267904 -> 1852425292768
	1852425292768 [label=AccumulateGrad]
	1852425292672 -> 1852425292144
	1852043358512 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1852043358512 -> 1852425292672
	1852425292672 [label=AccumulateGrad]
	1852425291760 -> 1852425291664
	1852043358592 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	1852043358592 -> 1852425291760
	1852425291760 [label=AccumulateGrad]
	1852425291712 -> 1852425291664
	1852043358672 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	1852043358672 -> 1852425291712
	1852425291712 [label=AccumulateGrad]
	1852425291616 -> 1852425291184
	1852425291088 -> 1852425290224
	1852043359072 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1852043359072 -> 1852425291088
	1852425291088 [label=AccumulateGrad]
	1852425290176 -> 1852425266512
	1852043359152 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	1852043359152 -> 1852425290176
	1852425290176 [label=AccumulateGrad]
	1852425290080 -> 1852425266512
	1852043359232 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	1852043359232 -> 1852425290080
	1852425290080 [label=AccumulateGrad]
	1852425265648 -> 1852425265456
	1852043359712 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1852043359712 -> 1852425265648
	1852425265648 [label=AccumulateGrad]
	1852425265552 -> 1852425266224
	1852043359632 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	1852043359632 -> 1852425265552
	1852425265552 [label=AccumulateGrad]
	1852425266032 -> 1852425266224
	1852043359792 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	1852043359792 -> 1852425266032
	1852425266032 [label=AccumulateGrad]
	1852425266080 -> 1852425266560
	1852043360192 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1852043360192 -> 1852425266080
	1852425266080 [label=AccumulateGrad]
	1852425266128 -> 1852425267280
	1852043360272 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	1852043360272 -> 1852425266128
	1852425266128 [label=AccumulateGrad]
	1852425266608 -> 1852425267280
	1852043360352 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	1852043360352 -> 1852425266608
	1852425266608 [label=AccumulateGrad]
	1852425267088 -> 1852425267232
	1852425267808 -> 1852425267568
	1852043361392 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	1852043361392 -> 1852425267808
	1852425267808 [label=AccumulateGrad]
	1852425267664 -> 1852425267184
	1852043361472 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1852043361472 -> 1852425267664
	1852425267664 [label=AccumulateGrad]
	1852425268336 -> 1852425267184
	1852043361552 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1852043361552 -> 1852425268336
	1852425268336 [label=AccumulateGrad]
	1852425266464 -> 1852425268192
	1852043362032 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1852043362032 -> 1852425266464
	1852425266464 [label=AccumulateGrad]
	1852425267712 -> 1852425268864
	1852043361952 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1852043361952 -> 1852425267712
	1852425267712 [label=AccumulateGrad]
	1852425268672 -> 1852425268864
	1852043362112 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1852043362112 -> 1852425268672
	1852425268672 [label=AccumulateGrad]
	1852425268720 -> 1852425269152
	1852043469104 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1852043469104 -> 1852425268720
	1852425268720 [label=AccumulateGrad]
	1852425268768 -> 1852425266896
	1852043469184 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	1852043469184 -> 1852425268768
	1852425268768 [label=AccumulateGrad]
	1852425269104 -> 1852425266896
	1852043469264 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	1852043469264 -> 1852425269104
	1852425269104 [label=AccumulateGrad]
	1852425269056 -> 1852425269008
	1852425269056 [label=CudnnBatchNormBackward0]
	1852425241600 -> 1852425269056
	1852425241600 [label=ConvolutionBackward0]
	1852425266656 -> 1852425241600
	1852425242176 -> 1852425241600
	1852043360752 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	1852043360752 -> 1852425242176
	1852425242176 [label=AccumulateGrad]
	1852425241648 -> 1852425269056
	1852043360832 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	1852043360832 -> 1852425241648
	1852425241648 [label=AccumulateGrad]
	1852425240640 -> 1852425269056
	1852043360912 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	1852043360912 -> 1852425240640
	1852425240640 [label=AccumulateGrad]
	1852425268576 -> 1852425268048
	1852043469584 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1852043469584 -> 1852425268576
	1852425268576 [label=AccumulateGrad]
	1852425268000 -> 1852425267952
	1852043469664 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1852043469664 -> 1852425268000
	1852425268000 [label=AccumulateGrad]
	1852425267520 -> 1852425267952
	1852043469744 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1852043469744 -> 1852425267520
	1852425267520 [label=AccumulateGrad]
	1852425267424 -> 1852425266848
	1852043470224 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1852043470224 -> 1852425267424
	1852425267424 [label=AccumulateGrad]
	1852425266416 -> 1852425266368
	1852043470144 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1852043470144 -> 1852425266416
	1852425266416 [label=AccumulateGrad]
	1852425265936 -> 1852425266368
	1852043470304 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1852043470304 -> 1852425265936
	1852425265936 [label=AccumulateGrad]
	1852425265840 -> 1852425265360
	1852043470704 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1852043470704 -> 1852425265840
	1852425265840 [label=AccumulateGrad]
	1852425265312 -> 1852043891184
	1852043470784 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	1852043470784 -> 1852425265312
	1852425265312 [label=AccumulateGrad]
	1852425265264 -> 1852043891184
	1852043470864 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	1852043470864 -> 1852425265264
	1852425265264 [label=AccumulateGrad]
	1852043891856 -> 1852043890992
	1852043891952 -> 1852425339136
	1852043471264 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1852043471264 -> 1852043891952
	1852043891952 [label=AccumulateGrad]
	1852425338944 -> 1852425339760
	1852043471344 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	1852043471344 -> 1852425338944
	1852425338944 [label=AccumulateGrad]
	1852425339424 -> 1852425339760
	1852043471424 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	1852043471424 -> 1852425339424
	1852425339424 [label=AccumulateGrad]
	1852425339232 -> 1852425340000
	1852043471904 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1852043471904 -> 1852425339232
	1852425339232 [label=AccumulateGrad]
	1852425339952 -> 1852425339808
	1851941412432 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	1851941412432 -> 1852425339952
	1852425339952 [label=AccumulateGrad]
	1852425339376 -> 1852425339808
	1852043471664 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	1852043471664 -> 1852425339376
	1852425339376 [label=AccumulateGrad]
	1852425340384 -> 1852425340288
	1852043472304 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1852043472304 -> 1852425340384
	1852425340384 [label=AccumulateGrad]
	1852425340960 -> 1852425340912
	1852043472384 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	1852043472384 -> 1852425340960
	1852425340960 [label=AccumulateGrad]
	1852425340720 -> 1852425340912
	1852043472464 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	1852043472464 -> 1852425340720
	1852425340720 [label=AccumulateGrad]
	1852425341104 -> 1852425340672
	1852425340096 -> 1852425340144
	1852425340096 [label=TBackward0]
	1852043892336 -> 1852425340096
	1851941308352 [label="fc.weight
 (3, 2048)" fillcolor=lightblue]
	1851941308352 -> 1852043892336
	1852043892336 [label=AccumulateGrad]
	1852425340144 -> 1852327747968
	dpi=300
}
