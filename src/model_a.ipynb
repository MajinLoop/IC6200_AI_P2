{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc88004-4ff7-4097-a9c8-f5f747b3f59f",
   "metadata": {},
   "source": [
    "<!-- PROJECT LOGO -->\n",
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"https://res.cloudinary.com/dek4evg4t/image/upload/v1729273000/Group_4.png\" alt=\"Logo\" width=\"30%\">\n",
    "  </a>\n",
    "</div>\n",
    "\n",
    "### 🖹 Descripción:\n",
    "El Proyecto II tiene como objetivo aplicar redes neuronales convolucionales (CNN) para realizar una clasificación multiclase de imágenes mediante aprendizaje supervisado. Utilizando el [Covid-19 Image Dataset de Kaggle](https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset), que contiene imágenes de rayos X clasificadas en tres categorías (Covid-19, Normal, Neumonía), en este proyecto se desarrollarán clasificadores capaces de diagnosticar enfermedades pulmonares. El proyecto también explora el uso de PyTorch para el desarrollo de modelos de Machine Learning y herramientas de monitoreo, como Weights and Biases, para el seguimiento en tiempo real del proceso de entrenamiento.\n",
    "\n",
    "### 👣 Pasos a seguir:\n",
    "\n",
    "1. Importación de librerías\n",
    "2. Configuraciones Iniciales\n",
    "3. Preparación de datos\n",
    "4. Definición del modelo\n",
    "5. Ajuste de hiperparámetros\n",
    "6. Entrenamiento del modelo\n",
    "7. Evaluación del modelo\n",
    "\n",
    "### ✍️ Autores:\n",
    "* Angelo Ortiz Vega - [@angelortizv](https://github.com/angelortizv)\n",
    "* Alejandro Campos Abarca - [@MajinLoop](https://github.com/MajinLoop)\n",
    "\n",
    "### 📅 Fecha:\n",
    "20 de octubre de 2024\n",
    "\n",
    "### 📝 Notas:\n",
    "Este es el segundo proyecto del curso IC6200 - Inteligencia Artificial. En este notebook, titulado \"Covid-19 Classification\", se profundiza en técnicas de data augmentation, preprocesamiento de imágenes con filtros, y fine-tuning de modelos CNN como VGG16 para mejorar la capacidad de generalización de las redes neuronales convolucionales.\n",
    "\n",
    "### Otras notas:\n",
    "Asegurarse de contar con Python y las siguientes bibliotecas instaladas: torch, torchvision, cv2, numpy, matplotlib, Pillow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718ba26-5ca1-4716-b8c8-06013cea193d",
   "metadata": {},
   "source": [
    "# Paso 1: Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a335a33a-976f-4d14-9cd8-d03a449f4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe626de8-6097-4c58-8414-7cf266ffabb3",
   "metadata": {},
   "source": [
    "# Paso 2: Configuraciones Iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6149f-bff2-4c74-8068-931b08d43ae8",
   "metadata": {},
   "source": [
    "## 2.1. Verificación de estado de CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5713dc4-01de-4c20-8380-a872ea57d07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n"
     ]
    }
   ],
   "source": [
    "u.check_cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620e9bc-6b6d-4c4b-b7fd-06098f4e68aa",
   "metadata": {},
   "source": [
    "## 2.2. Configuración de Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3163c12c-d1e1-457a-8277-1533a56f71c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6fu1dlfc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-feather-1</strong> at: <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/6fu1dlfc' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/6fu1dlfc</a><br/> View project at: <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_160859-6fu1dlfc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6fu1dlfc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\PC MASTER\\desktop\\ic6200\\proyectos\\IC6200_AI_P2\\src\\wandb\\run-20241018_161017-oi4eqiub</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/oi4eqiub' target=\"_blank\">hopeful-bush-2</a></strong> to <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/oi4eqiub' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/oi4eqiub</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"Covid19-CNN-Classification\", entity=\"angelortizv-tecnologico-de-costa-rica\") \n",
    "wandb.config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e6306-ad20-47e4-81c7-f5fb3599acc6",
   "metadata": {},
   "source": [
    "# Paso 3: Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15b40e0b-7762-4962-ad4c-8264c3038486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder('data/Covid19-dataset/train', transform=transform)\n",
    "    test_dataset = datasets.ImageFolder('data/Covid19-dataset/test', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Cargar datos\n",
    "train_loader, test_loader = get_data_loaders(wandb.config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a43c8-848f-43fc-97d3-3435e67aa2ac",
   "metadata": {},
   "source": [
    "# Paso 4: Definición del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90e1fb2d-55f4-484f-ade5-3b30a1ed6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "weights = VGG16_Weights.DEFAULT  # Puedes usar IMAGENET1K_V1 si lo prefieres\n",
    "model = models.vgg16(weights=weights)\n",
    "model.classifier[6] = nn.Linear(4096, 3)  # Cambiar la salida a 3 clases\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccb7c0-b920-4a80-b139-c2b1f0d1cc23",
   "metadata": {},
   "source": [
    "# Paso 5: Ajuste de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "955242d4-02e2-4fcd-b851-be2b548ce6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 19:26:33,232] A new study created in memory with name: no-name-be2cd131-a226-428c-968f-d187a259eab4\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:33:01,438] Trial 0 finished with value: 0.696969696969697 and parameters: {'batch_size': 64, 'learning_rate': 0.0005657289008117036}. Best is trial 0 with value: 0.696969696969697.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:33:56,475] Trial 1 finished with value: 0.3939393939393939 and parameters: {'batch_size': 16, 'learning_rate': 0.008119296630809961}. Best is trial 0 with value: 0.696969696969697.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:34:51,322] Trial 2 finished with value: 0.9848484848484849 and parameters: {'batch_size': 32, 'learning_rate': 1.4559871279534212e-05}. Best is trial 2 with value: 0.9848484848484849.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:35:45,589] Trial 3 finished with value: 0.7575757575757576 and parameters: {'batch_size': 32, 'learning_rate': 0.0010911909172219257}. Best is trial 2 with value: 0.9848484848484849.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:42:21,004] Trial 4 finished with value: 0.30303030303030304 and parameters: {'batch_size': 64, 'learning_rate': 0.0038955960967395693}. Best is trial 2 with value: 0.9848484848484849.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:43:15,384] Trial 5 finished with value: 0.3939393939393939 and parameters: {'batch_size': 32, 'learning_rate': 0.0014667266938692247}. Best is trial 2 with value: 0.9848484848484849.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:44:09,897] Trial 6 finished with value: 1.0 and parameters: {'batch_size': 32, 'learning_rate': 2.6853468906306184e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:45:04,692] Trial 7 finished with value: 0.3939393939393939 and parameters: {'batch_size': 32, 'learning_rate': 0.09643759711686758}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:46:00,793] Trial 8 finished with value: 0.9393939393939394 and parameters: {'batch_size': 16, 'learning_rate': 0.0001298946277609771}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:46:55,874] Trial 9 finished with value: 0.3939393939393939 and parameters: {'batch_size': 32, 'learning_rate': 0.004398510547450913}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:47:50,285] Trial 10 finished with value: 0.7878787878787878 and parameters: {'batch_size': 16, 'learning_rate': 1.1392125997389519e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:48:44,354] Trial 11 finished with value: 0.9848484848484849 and parameters: {'batch_size': 32, 'learning_rate': 1.4652957048788912e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:49:39,259] Trial 12 finished with value: 0.9848484848484849 and parameters: {'batch_size': 32, 'learning_rate': 8.55807435120876e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:50:32,844] Trial 13 finished with value: 1.0 and parameters: {'batch_size': 32, 'learning_rate': 5.727509989298248e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:51:26,764] Trial 14 finished with value: 0.9696969696969697 and parameters: {'batch_size': 32, 'learning_rate': 8.788235515399241e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:57:53,305] Trial 15 finished with value: 0.9090909090909091 and parameters: {'batch_size': 64, 'learning_rate': 4.577058252496097e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:58:47,657] Trial 16 finished with value: 0.9090909090909091 and parameters: {'batch_size': 32, 'learning_rate': 0.0003254549154113931}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:59:41,747] Trial 17 finished with value: 0.9696969696969697 and parameters: {'batch_size': 32, 'learning_rate': 3.494875135131245e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 20:00:36,684] Trial 18 finished with value: 0.8181818181818182 and parameters: {'batch_size': 16, 'learning_rate': 0.0002582322582852933}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 20:07:03,381] Trial 19 finished with value: 1.0 and parameters: {'batch_size': 64, 'learning_rate': 3.051841994491222e-05}. Best is trial 6 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros:\n",
      "{'batch_size': 32, 'learning_rate': 2.6853468906306184e-05}\n",
      "Mejor precisión: 1.0\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Hiperparámetros a ajustar\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    num_epochs = 10\n",
    "\n",
    "    # Cargar datos\n",
    "    train_loader, test_loader = get_data_loaders(batch_size)\n",
    "\n",
    "    # Reiniciar el modelo\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    model.classifier[6] = nn.Linear(4096, 3)  # Cambiar la salida a 3 clases\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Definir el optimizador y la función de pérdida\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenamiento\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Reiniciar gradientes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass y optimización\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    wandb.log({\"accuracy\": accuracy})\n",
    "    return accuracy\n",
    "\n",
    "# Ejecutar Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(study.best_params)\n",
    "print(\"Mejor precisión:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d710dbc-75d4-4d87-aa78-d2c89a2969af",
   "metadata": {},
   "source": [
    "# Paso 6: Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39771032-9547-4174-a0f6-6130a832690e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m):\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'epochs'"
     ]
    }
   ],
   "source": [
    "# Paso 6: Entrenamiento del modelo\n",
    "# Utiliza el mejor conjunto de hiperparámetros encontrados\n",
    "best_params = study.best_params\n",
    "batch_size = best_params['batch_size']\n",
    "learning_rate = best_params['learning_rate']\n",
    "\n",
    "# Reentrenar el modelo con los mejores hiperparámetros\n",
    "train_loader, test_loader = get_data_loaders(batch_size)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(wandb.config.epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    wandb.log({\"loss\": loss.item(), \"epoch\": epoch})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca9390-b54a-4589-b27a-9c7eb1867ac0",
   "metadata": {},
   "source": [
    "# Paso 7: Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589df1e4-c071-47b5-bd1c-29be8351009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 7: Evaluación del modelo\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Precisión del modelo: {accuracy * 100:.2f}%\")\n",
    "wandb.log({\"final_accuracy\": accuracy})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda08d5-b12c-413d-a7d2-1da97b9ec10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
