{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc88004-4ff7-4097-a9c8-f5f747b3f59f",
   "metadata": {},
   "source": [
    "<!-- PROJECT LOGO -->\n",
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"https://res.cloudinary.com/dek4evg4t/image/upload/v1729273000/Group_4.png\" alt=\"Logo\" width=\"30%\">\n",
    "  </a>\n",
    "</div>\n",
    "\n",
    "### 🖹 Descripción:\n",
    "Este Proyecto tiene como objetivo aplicar redes neuronales convolucionales (CNN) para realizar una clasificación multiclase de imágenes mediante aprendizaje supervisado. Utilizando el [Covid-19 Image Dataset de Kaggle](https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset), que contiene imágenes de rayos X clasificadas en tres categorías (Covid-19, Normal, Neumonía), en este proyecto se desarrollarán clasificadores capaces de diagnosticar enfermedades pulmonares. El proyecto también explora el uso de PyTorch para el desarrollo de modelos de Machine Learning y herramientas de monitoreo, como Weights and Biases, para el seguimiento en tiempo real del proceso de entrenamiento.\n",
    "\n",
    "### ✍️ Autores:\n",
    "* Angelo Ortiz Vega - [@angelortizv](https://github.com/angelortizv)\n",
    "* Alejandro Campos Abarca - [@MajinLoop](https://github.com/MajinLoop)\n",
    "\n",
    "### 📅 Fecha:\n",
    "20 de octubre de 2024\n",
    "\n",
    "### 📝 Notas:\n",
    "Este es el segundo proyecto del curso IC6200 - Inteligencia Artificial. En este notebook, titulado \"Covid-19 Classification\", se profundiza en técnicas de data augmentation, preprocesamiento de imágenes con filtros, y fine-tuning de modelos CNN como VGG16 para mejorar la capacidad de generalización de las redes neuronales convolucionales.\n",
    "\n",
    "### Otras notas:\n",
    "Asegurarse de contar con Python y las siguientes bibliotecas instaladas: torch, torchvision, cv2, numpy, matplotlib, Pillow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718ba26-5ca1-4716-b8c8-06013cea193d",
   "metadata": {},
   "source": [
    "#  1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a335a33a-976f-4d14-9cd8-d03a449f4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchviz import make_dot\n",
    "os.environ[\"PATH\"] += r\";C:\\Program Files\\Graphviz\\bin\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import wandb\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import utils as u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe626de8-6097-4c58-8414-7cf266ffabb3",
   "metadata": {},
   "source": [
    "#  2. Configuraciones Iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de2c098d-b7ef-4276-8e28-ba57459e232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = 'data/Covid19-dataset/train'\n",
    "TEST_DATA_PATH = 'data/Covid19-dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6149f-bff2-4c74-8068-931b08d43ae8",
   "metadata": {},
   "source": [
    "## 2.1. Verificación de estado de CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5713dc4-01de-4c20-8380-a872ea57d07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n"
     ]
    }
   ],
   "source": [
    "u.check_cuda_info()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620e9bc-6b6d-4c4b-b7fd-06098f4e68aa",
   "metadata": {},
   "source": [
    "## 2.2. Configuración de Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3163c12c-d1e1-457a-8277-1533a56f71c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: angelortizv (angelortizv-tecnologico-de-costa-rica). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\PC MASTER\\desktop\\ic6200\\proyectos\\IC6200_AI_P2\\src\\wandb\\run-20241020_230508-tpkg8iai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a/runs/tpkg8iai' target=\"_blank\">worldly-dew-3</a></strong> to <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a/runs/tpkg8iai' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a/runs/tpkg8iai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"CovMedNet_modelo_a\", entity=\"angelortizv-tecnologico-de-costa-rica\") \n",
    "wandb.config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e6306-ad20-47e4-81c7-f5fb3599acc6",
   "metadata": {},
   "source": [
    "#  3. Preprocesamiento y data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc4338-6587-4293-b4b9-0540a79c0f5e",
   "metadata": {},
   "source": [
    "## 3.1. Funciones de preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859ebf32-a48e-4280-b36e-f83ca94a9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bilateral_filter(image):\n",
    "    image = np.array(image)\n",
    "    filtered_image = cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    return Image.fromarray(filtered_image)\n",
    "\n",
    "def apply_canny_edge_filter(image):\n",
    "    image = np.array(image)\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return Image.fromarray(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b40e0b-7762-4962-ad4c-8264c3038486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"data_transforms = {\n",
    "    'raw': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'bilateral': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Lambda(lambda x: cv2.bilateralFilter(np.array(x).astype(np.float32), 9, 75, 75)),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'canny': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Lambda(lambda x: cv2.Canny(np.array(x), 100, 200)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}\"\"\"\n",
    "\n",
    "data_transforms = {\n",
    "    'raw': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'bilateral': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Lambda(apply_bilateral_filter),  # Aplicar Bilateral Filter\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'canny': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Lambda(apply_canny_edge_filter),  # Aplicar Canny Edge Filter\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a43c8-848f-43fc-97d3-3435e67aa2ac",
   "metadata": {},
   "source": [
    "#  4. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e1fb2d-55f4-484f-ade5-3b30a1ed6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/Covid19-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f104a1de-bb3f-4010-a8dc-64393f4d4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/train\",\n",
    "                                          transform=data_transforms[x])\n",
    "                  for x in ['raw', 'bilateral', 'canny']}\n",
    "\n",
    "test_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/test\",\n",
    "                                         transform=data_transforms[x])\n",
    "                 for x in ['raw', 'bilateral', 'canny']}\n",
    "\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True)\n",
    "               for x in ['raw', 'bilateral', 'canny']}\n",
    "\n",
    "test_dataloaders = {x: DataLoader(test_datasets[x], batch_size=32, shuffle=False)\n",
    "                    for x in ['raw', 'bilateral', 'canny']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccb7c0-b920-4a80-b139-c2b1f0d1cc23",
   "metadata": {},
   "source": [
    "#  5. Selección del Modelo A - ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bcdd5-1e39-488b-8f65-7bff3ed4cc7f",
   "metadata": {},
   "source": [
    "Razones de elección Resnet\n",
    "\n",
    "- **Arquitectura Profunda**: ResNet50 tiene 50 capas, lo que le permite aprender representaciones de alto nivel y características complejas sin sufrir el problema del desvanecimiento del gradiente.\n",
    "- **Conexiones Residuales**: Estas conexiones permiten que la red aprenda funciones de identidad, facilitando el entrenamiento de redes más profundas. Las conexiones residuales permiten que la información fluya más fácilmente a través de la red, lo que mejora la estabilidad del entrenamiento.\n",
    "- **Rendimiento Sólido**: Ha demostrado ser altamente efectiva en competiciones de clasificación de imágenes, como ImageNet, donde ha logrado clasificaciones superiores.\n",
    "- **Transfer Learning**: Utiliza pesos preentrenados de ImageNet, lo que ahorra tiempo y recursos, además de proporcionar un buen punto de partida para la clasificación en tareas específicas con conjuntos de datos más pequeños.\n",
    "- **Flexibilidad**: Se puede personalizar fácilmente para diferentes tareas de clasificación ajustando la capa final sin necesidad de rediseñar toda la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "955242d4-02e2-4fcd-b851-be2b548ce6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet50_Weights.IMAGENET1K_V1  # Cargar los pesos preentrenados\n",
    "model_a = models.resnet50(weights=weights)\n",
    "#model_a.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "num_ftrs = model_a.fc.in_features\n",
    "model_a.fc = nn.Linear(num_ftrs, 3)  # 3 clases: Covid-19, Normal, Viral Pneumonia\n",
    "model_a = model_a.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d710a0-b2c0-4f94-83fe-754bff3c17df",
   "metadata": {},
   "source": [
    "El código comienza cargando los pesos preentrenados de **ResNet50** desde el conjunto de datos **ImageNet** utilizando `ResNet50_Weights.IMAGENET1K_V1`, lo que permite que el modelo aproveche el conocimiento adquirido previamente para reconocer características visuales. Luego, se inicializa el modelo ResNet50 con estos pesos mediante `models.resnet50(weights=weights)`. A continuación, se obtiene el número de características de la capa de salida del modelo original a través de `num_ftrs = model_a.fc.in_features`, y se reemplaza la capa final por una nueva capa lineal (`nn.Linear`) que está configurada para clasificar tres clases específicas: **Covid-19**, **Normal** y **Viral Pneumonia**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff4a243-c88d-4f62-a202-7c6699f7ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 3]           6,147\n",
      "================================================================\n",
      "Total params: 23,514,179\n",
      "Trainable params: 23,514,179\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.70\n",
      "Estimated Total Size (MB): 376.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_a, (3, 224, 224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f10ac4-c0bc-4063-84e1-0329f784da14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet50_architecture.pdf'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir la transformación para convertir a escala de grises\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convertir a 3 canales (RGB)\n",
    "    transforms.Resize((224, 224)),  # Redimensionar a 224x224\n",
    "    transforms.ToTensor()  # Convertir a tensor\n",
    "])\n",
    "\n",
    "dummy_image = Image.new('RGB', (224, 224), color='white')  \n",
    "dummy_input = transform(dummy_image).unsqueeze(0).to(device) \n",
    "dummy_input = transform(dummy_image).unsqueeze(0).to(device) \n",
    "\n",
    "output = model_a(dummy_input)\n",
    "dot = make_dot(output, params=dict(list(model_a.named_parameters())))\n",
    "dot.render(\"resnet50_architecture\", format=\"png\") \n",
    "\n",
    "dot.view() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d710dbc-75d4-4d87-aa78-d2c89a2969af",
   "metadata": {},
   "source": [
    "#  6. Definición de función de pérdida y optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39771032-9547-4174-a0f6-6130a832690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_a = optim.Adam(model_a.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32342f28-e237-43c9-b8ea-8a19e87c28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(model_a, {'train': dataloaders['bilateral'], 'val': test_dataloaders['bilateral']}, criterion, optimizer_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827f836b-ca18-4043-82a1-a7395f2aaf74",
   "metadata": {},
   "source": [
    "#  7. Entrenamiento con los diferentes datasets y registro en W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2d6c6f3-03c5-4328-a42c-bd7825fc3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_wandb(model, dataloaders, criterion, optimizer, num_epochs=20, dataset_name=\"raw\"):\n",
    "    all_preds = []  \n",
    "    all_labels = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Fases de entrenamiento y validación\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Modo de entrenamiento\n",
    "            else:\n",
    "                model.eval()   # Modo de validación\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iteramos sobre los datos\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zerar gradientes\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Hacer forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Solo hacer backward en la fase de entrenamiento\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Actualizamos loss y accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Registro de métricas en W&B\n",
    "            if phase == 'val':\n",
    "                wandb.log({\n",
    "                    f\"{dataset_name}_val_loss\": epoch_loss,\n",
    "                    f\"{dataset_name}_val_acc\": epoch_acc\n",
    "                })\n",
    "            else:\n",
    "                wandb.log({\n",
    "                    f\"{dataset_name}_train_loss\": epoch_loss,\n",
    "                    f\"{dataset_name}_train_acc\": epoch_acc\n",
    "                })\n",
    "\n",
    "        if all_labels:  # Asegurarse de que hay etiquetas verdaderas\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=[f'Class {i}' for i in range(cm.shape[1])],\n",
    "                    yticklabels=[f'Class {i}' for i in range(cm.shape[1])])\n",
    "        plt.title(f'Confusion Matrix for {dataset_name}')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aab03720-7fc8-4f78-966a-0df6ae006f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.watch(model_a, log=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f147d7b3-40dd-4f28-a685-335bb06be212",
   "metadata": {},
   "source": [
    "## 7.1. Entrenar modelo con dataset crudo (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08176efe-76f7-412f-bad8-577f876645b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_with_wandb(model_a, {'train': dataloaders['raw'], 'val': test_dataloaders['raw']}, criterion, optimizer_a, dataset_name=\"raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabfb5e-f2da-4a93-94ee-e8e54372376a",
   "metadata": {},
   "source": [
    "## 7.2. Entrenar modelo con dataset filtrado bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f01f7822-324d-4b16-97b3-102716bc34a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "----------\n",
      "train Loss: 0.2011 Acc: 0.9442\n",
      "val Loss: 0.5030 Acc: 0.8485\n",
      "Epoch 2/25\n",
      "----------\n",
      "train Loss: 0.1194 Acc: 0.9562\n",
      "val Loss: 2.1469 Acc: 0.6970\n",
      "Epoch 3/25\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9841\n",
      "val Loss: 0.9055 Acc: 0.8939\n",
      "Epoch 4/25\n",
      "----------\n",
      "train Loss: 0.0335 Acc: 0.9841\n",
      "val Loss: 0.0273 Acc: 0.9848\n",
      "Epoch 5/25\n",
      "----------\n",
      "train Loss: 0.0760 Acc: 0.9681\n",
      "val Loss: 1.0801 Acc: 0.8182\n",
      "Epoch 6/25\n",
      "----------\n",
      "train Loss: 0.0947 Acc: 0.9641\n",
      "val Loss: 0.1294 Acc: 0.9242\n",
      "Epoch 7/25\n",
      "----------\n",
      "train Loss: 0.0351 Acc: 0.9920\n",
      "val Loss: 0.4144 Acc: 0.9091\n",
      "Epoch 8/25\n",
      "----------\n",
      "train Loss: 0.0166 Acc: 0.9960\n",
      "val Loss: 1.1925 Acc: 0.7727\n",
      "Epoch 9/25\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9880\n",
      "val Loss: 0.1501 Acc: 0.9242\n",
      "Epoch 10/25\n",
      "----------\n",
      "train Loss: 0.0587 Acc: 0.9801\n",
      "val Loss: 0.5010 Acc: 0.9242\n",
      "Epoch 11/25\n",
      "----------\n",
      "train Loss: 0.0573 Acc: 0.9761\n",
      "val Loss: 0.2355 Acc: 0.9242\n",
      "Epoch 12/25\n",
      "----------\n",
      "train Loss: 0.0409 Acc: 0.9880\n",
      "val Loss: 0.0062 Acc: 1.0000\n",
      "Epoch 13/25\n",
      "----------\n",
      "train Loss: 0.0195 Acc: 0.9880\n",
      "val Loss: 0.0672 Acc: 0.9697\n",
      "Epoch 14/25\n",
      "----------\n",
      "train Loss: 0.0105 Acc: 0.9960\n",
      "val Loss: 0.0251 Acc: 1.0000\n",
      "Epoch 15/25\n",
      "----------\n",
      "train Loss: 0.0166 Acc: 0.9960\n",
      "val Loss: 0.1359 Acc: 0.9394\n",
      "Epoch 16/25\n",
      "----------\n",
      "train Loss: 0.0122 Acc: 1.0000\n",
      "val Loss: 0.0974 Acc: 0.9394\n",
      "Epoch 17/25\n",
      "----------\n",
      "train Loss: 0.0188 Acc: 0.9960\n",
      "val Loss: 0.0352 Acc: 1.0000\n",
      "Epoch 18/25\n",
      "----------\n",
      "train Loss: 0.0374 Acc: 0.9920\n",
      "val Loss: 2.2905 Acc: 0.7121\n",
      "Epoch 19/25\n",
      "----------\n",
      "train Loss: 0.0346 Acc: 0.9841\n",
      "val Loss: 0.2430 Acc: 0.9242\n",
      "Epoch 20/25\n",
      "----------\n",
      "train Loss: 0.0252 Acc: 0.9920\n",
      "val Loss: 0.1935 Acc: 0.9394\n",
      "Epoch 21/25\n",
      "----------\n",
      "train Loss: 0.0165 Acc: 0.9960\n",
      "val Loss: 0.1861 Acc: 0.9697\n",
      "Epoch 22/25\n",
      "----------\n",
      "train Loss: 0.0450 Acc: 0.9761\n",
      "val Loss: 0.8279 Acc: 0.8182\n",
      "Epoch 23/25\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 1.0000\n",
      "val Loss: 0.4299 Acc: 0.8485\n",
      "Epoch 24/25\n",
      "----------\n",
      "train Loss: 0.0391 Acc: 0.9841\n",
      "val Loss: 0.1142 Acc: 0.9545\n",
      "Epoch 25/25\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 0.9920\n",
      "val Loss: 0.1057 Acc: 0.9697\n"
     ]
    }
   ],
   "source": [
    "train_model_with_wandb(model_a, {'train': dataloaders['bilateral'], 'val': test_dataloaders['bilateral']}, criterion, optimizer_a, dataset_name=\"bilateral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59804ab0-cfa4-4962-b757-84c716d096b8",
   "metadata": {},
   "source": [
    "## 7.3. Entrenar modelo con dataset con filtro Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cb5bd932-f677-48e9-8f2c-f3a1648a42fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "----------\n",
      "train Loss: 1.1291 Acc: 0.7530\n",
      "val Loss: 5.4246 Acc: 0.3485\n",
      "Epoch 2/25\n",
      "----------\n",
      "train Loss: 0.3640 Acc: 0.8566\n",
      "val Loss: 5.6982 Acc: 0.3030\n",
      "Epoch 3/25\n",
      "----------\n",
      "train Loss: 0.3675 Acc: 0.8207\n",
      "val Loss: 5.2198 Acc: 0.3636\n",
      "Epoch 4/25\n",
      "----------\n",
      "train Loss: 0.2993 Acc: 0.8845\n",
      "val Loss: 14.2764 Acc: 0.3182\n",
      "Epoch 5/25\n",
      "----------\n",
      "train Loss: 0.2379 Acc: 0.9283\n",
      "val Loss: 1.1999 Acc: 0.7273\n",
      "Epoch 6/25\n",
      "----------\n",
      "train Loss: 0.1266 Acc: 0.9522\n",
      "val Loss: 0.4790 Acc: 0.8333\n",
      "Epoch 7/25\n",
      "----------\n",
      "train Loss: 0.1246 Acc: 0.9602\n",
      "val Loss: 1.1682 Acc: 0.6970\n",
      "Epoch 8/25\n",
      "----------\n",
      "train Loss: 0.1029 Acc: 0.9602\n",
      "val Loss: 0.3262 Acc: 0.8485\n",
      "Epoch 9/25\n",
      "----------\n",
      "train Loss: 0.0927 Acc: 0.9641\n",
      "val Loss: 0.6877 Acc: 0.7879\n",
      "Epoch 10/25\n",
      "----------\n",
      "train Loss: 0.0945 Acc: 0.9641\n",
      "val Loss: 0.8625 Acc: 0.7121\n",
      "Epoch 11/25\n",
      "----------\n",
      "train Loss: 0.0273 Acc: 0.9920\n",
      "val Loss: 1.5759 Acc: 0.5758\n",
      "Epoch 12/25\n",
      "----------\n",
      "train Loss: 0.0325 Acc: 0.9960\n",
      "val Loss: 0.4374 Acc: 0.8788\n",
      "Epoch 13/25\n",
      "----------\n",
      "train Loss: 0.0208 Acc: 0.9920\n",
      "val Loss: 0.5771 Acc: 0.7727\n",
      "Epoch 14/25\n",
      "----------\n",
      "train Loss: 0.0225 Acc: 0.9920\n",
      "val Loss: 0.2553 Acc: 0.8939\n",
      "Epoch 15/25\n",
      "----------\n",
      "train Loss: 0.0130 Acc: 1.0000\n",
      "val Loss: 0.5774 Acc: 0.8939\n",
      "Epoch 16/25\n",
      "----------\n",
      "train Loss: 0.0052 Acc: 1.0000\n",
      "val Loss: 0.4865 Acc: 0.8636\n",
      "Epoch 17/25\n",
      "----------\n",
      "train Loss: 0.0039 Acc: 1.0000\n",
      "val Loss: 0.4102 Acc: 0.8333\n",
      "Epoch 18/25\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 1.0000\n",
      "val Loss: 1.1741 Acc: 0.7727\n",
      "Epoch 19/25\n",
      "----------\n",
      "train Loss: 0.0034 Acc: 1.0000\n",
      "val Loss: 0.8048 Acc: 0.7727\n",
      "Epoch 20/25\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 1.0000\n",
      "val Loss: 0.5325 Acc: 0.8485\n",
      "Epoch 21/25\n",
      "----------\n",
      "train Loss: 0.0015 Acc: 1.0000\n",
      "val Loss: 0.4955 Acc: 0.8485\n",
      "Epoch 22/25\n",
      "----------\n",
      "train Loss: 0.0010 Acc: 1.0000\n",
      "val Loss: 0.5329 Acc: 0.8636\n",
      "Epoch 23/25\n",
      "----------\n",
      "train Loss: 0.0022 Acc: 1.0000\n",
      "val Loss: 0.4655 Acc: 0.8636\n",
      "Epoch 24/25\n",
      "----------\n",
      "train Loss: 0.0006 Acc: 1.0000\n",
      "val Loss: 0.5378 Acc: 0.8636\n",
      "Epoch 25/25\n",
      "----------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "val Loss: 0.4379 Acc: 0.8788\n"
     ]
    }
   ],
   "source": [
    "model_a.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model_a = model_a.to(device)\n",
    "\n",
    "train_model_with_wandb(model_a, {'train': dataloaders['canny'], 'val': test_dataloaders['canny']}, criterion, optimizer_a, dataset_name=\"canny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3026f7-9a09-4df9-b89d-d3cde95a9621",
   "metadata": {},
   "source": [
    "# 8. Exportar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b84ac498-2d61-453d-8c72-1af74f5966ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_a.state_dict(), 'model_a.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "07e28407-12ec-4dc4-adce-6c962575cde9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bilateral_train_acc</td><td>▁▃▆▆▄▄▇█▇▆▅▇▇████▇▆▇█▅█▆▇</td></tr><tr><td>bilateral_train_loss</td><td>█▅▃▂▄▄▂▁▂▃▃▂▂▁▁▁▂▂▂▂▁▂▁▂▂</td></tr><tr><td>bilateral_val_acc</td><td>▅▁▆█▄▆▆▃▆▆▆█▇█▇▇█▁▆▇▇▄▅▇▇</td></tr><tr><td>bilateral_val_loss</td><td>▃█▄▁▄▁▂▅▁▃▂▁▁▁▁▁▁█▂▂▂▄▂▁▁</td></tr><tr><td>canny_train_acc</td><td>▁▄▃▅▆▇▇▇▇▇███████████████</td></tr><tr><td>canny_train_loss</td><td>█▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>canny_val_acc</td><td>▂▁▂▁▆▇▆▇▇▆▄█▇███▇▇▇▇▇████</td></tr><tr><td>canny_val_loss</td><td>▄▄▃█▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_train_acc</td><td>▁▃▃▄▆▅▇▇▇▆▇▇▇█████▇▇▇███▇</td></tr><tr><td>raw_train_loss</td><td>▇█▅▄▄▃▂▂▁▂▂▂▂▁▁▁▁▁▁▂▂▁▁▁▂</td></tr><tr><td>raw_val_acc</td><td>▄▁▅▆██▇▇█▆▂▃▆▇▇▆▅▇▆▆█▇▇█▇</td></tr><tr><td>raw_val_loss</td><td>▂█▂▂▁▁▁▁▁▁▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bilateral_train_acc</td><td>0.99203</td></tr><tr><td>bilateral_train_loss</td><td>0.02281</td></tr><tr><td>bilateral_val_acc</td><td>0.9697</td></tr><tr><td>bilateral_val_loss</td><td>0.10567</td></tr><tr><td>canny_train_acc</td><td>1</td></tr><tr><td>canny_train_loss</td><td>0.00131</td></tr><tr><td>canny_val_acc</td><td>0.87879</td></tr><tr><td>canny_val_loss</td><td>0.43786</td></tr><tr><td>raw_train_acc</td><td>0.9761</td></tr><tr><td>raw_train_loss</td><td>0.05026</td></tr><tr><td>raw_val_acc</td><td>0.86364</td></tr><tr><td>raw_val_loss</td><td>0.52032</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-breeze-2</strong> at: <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a/runs/fmq51tde' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a/runs/fmq51tde</a><br/> View project at: <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/CovMedNet_modelo_a</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241020_202810-fmq51tde\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ebb65-d70d-4ed5-b257-a3436962064c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
