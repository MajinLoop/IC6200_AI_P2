{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc88004-4ff7-4097-a9c8-f5f747b3f59f",
   "metadata": {},
   "source": [
    "<!-- PROJECT LOGO -->\n",
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"https://res.cloudinary.com/dek4evg4t/image/upload/v1729273000/Group_4.png\" alt=\"Logo\" width=\"30%\">\n",
    "  </a>\n",
    "</div>\n",
    "\n",
    "###  Descripci贸n:\n",
    "El Proyecto II tiene como objetivo aplicar redes neuronales convolucionales (CNN) para realizar una clasificaci贸n multiclase de im谩genes mediante aprendizaje supervisado. Utilizando el [Covid-19 Image Dataset de Kaggle](https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset), que contiene im谩genes de rayos X clasificadas en tres categor铆as (Covid-19, Normal, Neumon铆a), en este proyecto se desarrollar谩n clasificadores capaces de diagnosticar enfermedades pulmonares. El proyecto tambi茅n explora el uso de PyTorch para el desarrollo de modelos de Machine Learning y herramientas de monitoreo, como Weights and Biases, para el seguimiento en tiempo real del proceso de entrenamiento.\n",
    "\n",
    "###  Pasos a seguir:\n",
    "\n",
    "1. Importaci贸n de librer铆as\n",
    "2. Configuraciones Iniciales\n",
    "3. Preparaci贸n de datos\n",
    "4. Definici贸n del modelo\n",
    "5. Ajuste de hiperpar谩metros\n",
    "6. Entrenamiento del modelo\n",
    "7. Evaluaci贸n del modelo\n",
    "\n",
    "### 锔 Autores:\n",
    "* Angelo Ortiz Vega - [@angelortizv](https://github.com/angelortizv)\n",
    "* Alejandro Campos Abarca - [@MajinLoop](https://github.com/MajinLoop)\n",
    "\n",
    "###  Fecha:\n",
    "20 de octubre de 2024\n",
    "\n",
    "###  Notas:\n",
    "Este es el segundo proyecto del curso IC6200 - Inteligencia Artificial. En este notebook, titulado \"Covid-19 Classification\", se profundiza en t茅cnicas de data augmentation, preprocesamiento de im谩genes con filtros, y fine-tuning de modelos CNN como VGG16 para mejorar la capacidad de generalizaci贸n de las redes neuronales convolucionales.\n",
    "\n",
    "### Otras notas:\n",
    "Asegurarse de contar con Python y las siguientes bibliotecas instaladas: torch, torchvision, cv2, numpy, matplotlib, Pillow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718ba26-5ca1-4716-b8c8-06013cea193d",
   "metadata": {},
   "source": [
    "# Paso 1: Importaci贸n de librer铆as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a335a33a-976f-4d14-9cd8-d03a449f4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe626de8-6097-4c58-8414-7cf266ffabb3",
   "metadata": {},
   "source": [
    "# Paso 2: Configuraciones Iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6149f-bff2-4c74-8068-931b08d43ae8",
   "metadata": {},
   "source": [
    "## 2.1. Verificaci贸n de estado de CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5713dc4-01de-4c20-8380-a872ea57d07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n"
     ]
    }
   ],
   "source": [
    "u.check_cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620e9bc-6b6d-4c4b-b7fd-06098f4e68aa",
   "metadata": {},
   "source": [
    "## 2.2. Configuraci贸n de Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3163c12c-d1e1-457a-8277-1533a56f71c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6fu1dlfc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mild-feather-1</strong> at: <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/6fu1dlfc' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/6fu1dlfc</a><br/> View project at: <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_160859-6fu1dlfc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6fu1dlfc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\PC MASTER\\desktop\\ic6200\\proyectos\\IC6200_AI_P2\\src\\wandb\\run-20241018_161017-oi4eqiub</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/oi4eqiub' target=\"_blank\">hopeful-bush-2</a></strong> to <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/oi4eqiub' target=\"_blank\">https://wandb.ai/angelortizv-tecnologico-de-costa-rica/Covid19-CNN-Classification/runs/oi4eqiub</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"Covid19-CNN-Classification\", entity=\"angelortizv-tecnologico-de-costa-rica\") \n",
    "wandb.config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e6306-ad20-47e4-81c7-f5fb3599acc6",
   "metadata": {},
   "source": [
    "# Paso 3: Preparaci贸n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15b40e0b-7762-4962-ad4c-8264c3038486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder('data/Covid19-dataset/train', transform=transform)\n",
    "    test_dataset = datasets.ImageFolder('data/Covid19-dataset/test', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Cargar datos\n",
    "train_loader, test_loader = get_data_loaders(wandb.config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a43c8-848f-43fc-97d3-3435e67aa2ac",
   "metadata": {},
   "source": [
    "# Paso 4: Definici贸n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90e1fb2d-55f4-484f-ade5-3b30a1ed6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "weights = VGG16_Weights.DEFAULT  # Puedes usar IMAGENET1K_V1 si lo prefieres\n",
    "model = models.vgg16(weights=weights)\n",
    "model.classifier[6] = nn.Linear(4096, 3)  # Cambiar la salida a 3 clases\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccb7c0-b920-4a80-b139-c2b1f0d1cc23",
   "metadata": {},
   "source": [
    "# Paso 5: Ajuste de Hiperpar谩metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "955242d4-02e2-4fcd-b851-be2b548ce6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-18 19:26:33,232] A new study created in memory with name: no-name-be2cd131-a226-428c-968f-d187a259eab4\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:33:01,438] Trial 0 finished with value: 0.696969696969697 and parameters: {'batch_size': 64, 'learning_rate': 0.0005657289008117036}. Best is trial 0 with value: 0.696969696969697.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:33:56,475] Trial 1 finished with value: 0.3939393939393939 and parameters: {'batch_size': 16, 'learning_rate': 0.008119296630809961}. Best is trial 0 with value: 0.696969696969697.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:34:51,322] Trial 2 finished with value: 0.9848484848484849 and parameters: {'batch_size': 32, 'learning_rate': 1.4559871279534212e-05}. Best is trial 2 with value: 0.9848484848484849.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:35:45,589] Trial 3 finished with value: 0.7575757575757576 and parameters: {'batch_size': 32, 'learning_rate': 0.0010911909172219257}. Best is trial 2 with value: 0.9848484848484849.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:42:21,004] Trial 4 finished with value: 0.30303030303030304 and parameters: {'batch_size': 64, 'learning_rate': 0.0038955960967395693}. Best is trial 2 with value: 0.9848484848484849.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:43:15,384] Trial 5 finished with value: 0.3939393939393939 and parameters: {'batch_size': 32, 'learning_rate': 0.0014667266938692247}. Best is trial 2 with value: 0.9848484848484849.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:44:09,897] Trial 6 finished with value: 1.0 and parameters: {'batch_size': 32, 'learning_rate': 2.6853468906306184e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:45:04,692] Trial 7 finished with value: 0.3939393939393939 and parameters: {'batch_size': 32, 'learning_rate': 0.09643759711686758}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:46:00,793] Trial 8 finished with value: 0.9393939393939394 and parameters: {'batch_size': 16, 'learning_rate': 0.0001298946277609771}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:46:55,874] Trial 9 finished with value: 0.3939393939393939 and parameters: {'batch_size': 32, 'learning_rate': 0.004398510547450913}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:47:50,285] Trial 10 finished with value: 0.7878787878787878 and parameters: {'batch_size': 16, 'learning_rate': 1.1392125997389519e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:48:44,354] Trial 11 finished with value: 0.9848484848484849 and parameters: {'batch_size': 32, 'learning_rate': 1.4652957048788912e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:49:39,259] Trial 12 finished with value: 0.9848484848484849 and parameters: {'batch_size': 32, 'learning_rate': 8.55807435120876e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:50:32,844] Trial 13 finished with value: 1.0 and parameters: {'batch_size': 32, 'learning_rate': 5.727509989298248e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:51:26,764] Trial 14 finished with value: 0.9696969696969697 and parameters: {'batch_size': 32, 'learning_rate': 8.788235515399241e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:57:53,305] Trial 15 finished with value: 0.9090909090909091 and parameters: {'batch_size': 64, 'learning_rate': 4.577058252496097e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:58:47,657] Trial 16 finished with value: 0.9090909090909091 and parameters: {'batch_size': 32, 'learning_rate': 0.0003254549154113931}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 19:59:41,747] Trial 17 finished with value: 0.9696969696969697 and parameters: {'batch_size': 32, 'learning_rate': 3.494875135131245e-05}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 20:00:36,684] Trial 18 finished with value: 0.8181818181818182 and parameters: {'batch_size': 16, 'learning_rate': 0.0002582322582852933}. Best is trial 6 with value: 1.0.\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Temp\\ipykernel_35228\\1212401057.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC MASTER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[I 2024-10-18 20:07:03,381] Trial 19 finished with value: 1.0 and parameters: {'batch_size': 64, 'learning_rate': 3.051841994491222e-05}. Best is trial 6 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperpar谩metros:\n",
      "{'batch_size': 32, 'learning_rate': 2.6853468906306184e-05}\n",
      "Mejor precisi贸n: 1.0\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Hiperpar谩metros a ajustar\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    num_epochs = 10\n",
    "\n",
    "    # Cargar datos\n",
    "    train_loader, test_loader = get_data_loaders(batch_size)\n",
    "\n",
    "    # Reiniciar el modelo\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    model.classifier[6] = nn.Linear(4096, 3)  # Cambiar la salida a 3 clases\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Definir el optimizador y la funci贸n de p茅rdida\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenamiento\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Reiniciar gradientes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass y optimizaci贸n\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    wandb.log({\"accuracy\": accuracy})\n",
    "    return accuracy\n",
    "\n",
    "# Ejecutar Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Imprimir los mejores hiperpar谩metros\n",
    "print(\"Mejores hiperpar谩metros:\")\n",
    "print(study.best_params)\n",
    "print(\"Mejor precisi贸n:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d710dbc-75d4-4d87-aa78-d2c89a2969af",
   "metadata": {},
   "source": [
    "# Paso 6: Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39771032-9547-4174-a0f6-6130a832690e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m):\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'epochs'"
     ]
    }
   ],
   "source": [
    "# Paso 6: Entrenamiento del modelo\n",
    "# Utiliza el mejor conjunto de hiperpar谩metros encontrados\n",
    "best_params = study.best_params\n",
    "batch_size = best_params['batch_size']\n",
    "learning_rate = best_params['learning_rate']\n",
    "\n",
    "# Reentrenar el modelo con los mejores hiperpar谩metros\n",
    "train_loader, test_loader = get_data_loaders(batch_size)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(wandb.config.epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    wandb.log({\"loss\": loss.item(), \"epoch\": epoch})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca9390-b54a-4589-b27a-9c7eb1867ac0",
   "metadata": {},
   "source": [
    "# Paso 7: Evaluaci贸n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589df1e4-c071-47b5-bd1c-29be8351009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 7: Evaluaci贸n del modelo\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Precisi贸n del modelo: {accuracy * 100:.2f}%\")\n",
    "wandb.log({\"final_accuracy\": accuracy})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda08d5-b12c-413d-a7d2-1da97b9ec10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
